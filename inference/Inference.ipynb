{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bb32059-d9b5-4d02-8a05-ace7c0b9c6fd",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "045429cb-91e8-4909-90ad-9c161e91d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torch import nn\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421bf7d6-6e39-4599-b0ad-927702e6e81a",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b161a1-8a73-4c03-8ad5-5a45b5f7142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_LET = 'singlets'\n",
    "BATCH_SIZE = 32\n",
    "MAX_POOLED_EMBEDDING_SIZE = 64\n",
    "MAX_SEQ_LEN = 512\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "test_set_path = f\"yarongef/{K_LET}_test_set\"\n",
    "dataset_path = 'dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2bf66b-6d3e-40d9-9200-5c28bca1c9f9",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07202a67-239e-4ad8-a9d5-a09128c90a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(labels, preds):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    auroc = roc_auc_score(labels, preds)\n",
    "    return {\n",
    "        'Accuracy': acc,\n",
    "        'F1': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'AUC': auroc\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf376454-2482-499a-a29a-ad577b063aa8",
   "metadata": {},
   "source": [
    "Prepare test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac80fb6-2fe8-48b8-a835-f1e2929aabfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_set = torch.load(f'{dataset}{K_LET}').float()\n",
    "x_test_set = x_test_set.view(x_test_set.shape[0], x_test_set.shape[1]*x_test_set.shape[2])\n",
    "test_set = load_dataset(test_set_path)\n",
    "true_labels = torch.Tensor(test_set['test']['label'])\n",
    "x_test_set = x_test_set.to(device)\n",
    "test_dataset = TensorDataset(x_test_set)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9f5f5b-47e9-4498-8c3f-15714e84203b",
   "metadata": {},
   "source": [
    "Instantiate classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "076cd0f1-78e4-4925-b4de-e44f14b2b5a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/dsi/yarong/jupyter/DistilProtBert/Git uploads/model/singlets/model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-54d04716a53b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_Network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_SEQ_LEN\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mMAX_POOLED_EMBEDDING_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{cwd}/model/{K_LET}/model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/dsi/yarong/jupyter/DistilProtBert/Git uploads/model/singlets/model.pt'"
     ]
    }
   ],
   "source": [
    "class classify_Network(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super(classify_Network, self).__init__()\n",
    "        \n",
    "        # layers\n",
    "        self.linear = nn.Linear(hidden_dim, hidden_dim//32)\n",
    "        self.linear2 = nn.Linear(hidden_dim//32, hidden_dim//128)\n",
    "        self.linear3 = nn.Linear(hidden_dim//128, output_dim)\n",
    "        \n",
    "        # activation functions\n",
    "        self.hidden_activation = nn.ReLU()\n",
    "        self.last_activation = nn.Sigmoid()\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)   \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.hidden_activation(self.linear(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.hidden_activation(self.linear2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.last_activation(self.linear3(x))\n",
    "        return x.squeeze()\n",
    "    \n",
    "model = classify_Network(MAX_SEQ_LEN*MAX_POOLED_EMBEDDING_SIZE, 1)\n",
    "model.load_state_dict(torch.load(f'model/{K_LET}/model.pt')) # relative path to model folder\n",
    "model.to(device)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78efce5-29b0-47bb-9b10-a55509ecabfc",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e960cc0b-cb3a-4dd8-839c-77f00ac186eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    model.eval()\n",
    "    res = np.zeros((len(true_labels)))\n",
    "    i = 0\n",
    "    for inputs, in test_loader:\n",
    "        output = model(inputs)\n",
    "        output = torch.round(output)\n",
    "        res[i*BATCH_SIZE:i*BATCH_SIZE+BATCH_SIZE] = output.cpu().detach().numpy()\n",
    "        i += 1\n",
    "\n",
    "metrics = compute_metrics(true_labels, res)\n",
    "for metric in ress:\n",
    "    print(metric, metrics[metric])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
